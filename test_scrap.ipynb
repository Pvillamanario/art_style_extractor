{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import json\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pages = 0\n",
    "current_page = 0\n",
    "typology_index = 0\n",
    "\n",
    "path_images_thumbnails = './data/images_thumbnails/'\n",
    "path_images_numpy = './data/images_numpy/'\n",
    "path_annotations_json = './data/annotations_json/'\n",
    "path_annotations_pickle = './data/annotations_pickle/'\n",
    "\n",
    "url_base = 'https://collections.louvre.fr/en/recherche?page=1&typology%5B0%5D=1'\n",
    "url_scrap = f'https://collections.louvre.fr/en/recherche?page={current_page}&typology[{typology_index}]=1'\n",
    "url_art_DB_base = 'https://collections.louvre.fr'\n",
    "\n",
    "\n",
    "\n",
    "#typology = {'Peintures' : f'Typology[{typology_index}]=1'}\n",
    "\n",
    "# DOM content\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0'}\n",
    "# https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weblimits(url):\n",
    "\n",
    "    response = requests.get(url_base, headers=headers) #, timeout=0.2)\n",
    "    html = response.content\n",
    "    print(f'Status code is: {response.status_code}')\n",
    "\n",
    "    response = requests.get(url_base, headers=headers) #, timeout=0.05)\n",
    "    html = response.content\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    span = soup.find('input', class_='pagination__current nav__pagination__nbr no_style')\n",
    "    max_number_of_pages = int(span['max'])\n",
    "    current_page = int(span['value'])\n",
    "\n",
    "    print(f'There are {max_number_of_pages} pages to be scraped.\\n')\n",
    "\n",
    "    return max_number_of_pages, current_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artworks_links(url):\n",
    "\n",
    "    link_list = []\n",
    "\n",
    "    response = requests.get(url, headers=headers) #, timeout=0.2)\n",
    "    html = response.content\n",
    "    print(f'Status code is: {response.status_code}')\n",
    "\n",
    "    response = requests.get(url, headers=headers) #, timeout=0.05)\n",
    "    html = response.content\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    span = soup.findAll('a', class_='card--search card__link')\n",
    "\n",
    "    for i in range(0, len(span)):\n",
    "        link_list.append(span[i]['href'])\n",
    "\n",
    "    print(f'There are {len(link_list)} items in this page.\\n')    \n",
    "    return link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (753739853.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [21]\u001b[1;36m\u001b[0m\n\u001b[1;33m    annotations = f\"Key = {arkID}\\n\u001b[0m\n\u001b[1;37m                                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    " def get_items(links):\n",
    "\n",
    "    if os.path.exists(path_annotations_json):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path_annotations_json)\n",
    "\n",
    "    if os.path.exists(path_annotations_xml):\n",
    "        pass\n",
    "    else:\n",
    "        os.mkdir(path_annotations_xml)\n",
    "\n",
    "\n",
    "\n",
    "    for i in links:\n",
    "       \n",
    "        # Get item info\n",
    "        metadata = requests.get(url_art_DB_base+ i +'.json').content\n",
    "        print(f'./json/{i[-11:]}')\n",
    "\n",
    "        with open(f'{path_annotations_json}{i[-11:]}.json', 'wb') as f:\n",
    "            f.write(metadata)  \n",
    "\n",
    "        # Save item info as xml:\n",
    "        arkID = i[-11:]\n",
    "        startYear = metadata['dateCreated'][0]['startYear']\n",
    "        endYear = metadata['dateCreated'][0]['endYear']\n",
    "        collection = metadata['collection']\n",
    "        materialsAndTechniques = metadata['materialsAndTechniques']\n",
    "        category = metadata['index']['Category'][0]['value']\n",
    "        tags = []\n",
    "\n",
    "        for i in range(0,9):\n",
    "            # en el json hay 9 keys de imagenery_value\n",
    "            try: \n",
    "                imagenery_value = metadata['index']['Imagery'][i]['value']\n",
    "                tags.append(imagenery_value)\n",
    "            except:\n",
    "                imagenery_value = ''\n",
    "                tags.append(imagenery_value)\n",
    "\n",
    "        annotations = f\"Key = {arkID}\\n\n",
    "                    {'filename': '88.jpg',\n",
    "                    'flickr_url': 'https://www.flickr.com/photos/81273124@N00/14734618908/',\n",
    "                    'image_url': 'https://farm4.staticflickr.com/3877/14734618908_182577aa1e.jpg',\n",
    "                    'tags': {tags},\n",
    "                    'text': 'With in the 5th ward of Milwaukee, WI there has been a variety of '\n",
    "                            'changes. Many apartments, condos, restaurants, and bars have been '\n",
    "                            'added. The Courteen Seed Company building was created in 1913, and '\n",
    "                            \"has been abandoned since 1960's. In 2006, there were plans to \"\n",
    "                            'convert there warehouse to apartments/condos, yet minimal '\n",
    "                            'maintenance has been done.',\n",
    "                    'title': 'Courteen Seed Company VS The 5th Ward'}\"\n",
    "\n",
    "    \n",
    "\n",
    "        # Get item thumnail\n",
    "        thumbnail = requests.get(json.loads(metadata)['image'][0]['urlThumbnail']).content\n",
    "        print(json.loads(metadata)['image'][0]['urlThumbnail'])\n",
    "\n",
    "        with open(f'{path_images_thumbnails}{i[-11:]}.jpg', 'wb') as f:\n",
    "            f.write(thumbnail)\n",
    "\n",
    "\n",
    "def retrieve_img_annotations(ID):\n",
    "\n",
    "    # Opening JSON file\n",
    "    f = open(f'./data/img_annotations_json/{ID}.json')\n",
    " \n",
    "    # returns JSON object as\n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "\n",
    "    # Closing file\n",
    "    f.close()\n",
    "\n",
    "    arkID = ID\n",
    "    startYear = data['dateCreated'][0]['startYear']\n",
    "    endYear = data['dateCreated'][0]['endYear']\n",
    "    collection = data['collection']\n",
    "    materialsAndTechniques = data['materialsAndTechniques']\n",
    "    category = data['index']['Category'][0]['value']\n",
    "\n",
    "    #print(arkID)\n",
    "\n",
    "    try: \n",
    "        imagenery_value_1 = data['index']['Imagery'][0]['value']\n",
    "    except:\n",
    "        imagenery_value_1 = ''\n",
    "        #print('no annotation \\n')\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        imagenery_value_2 = data['index']['Imagery'][1]['value']\n",
    "    except:\n",
    "        imagenery_value_2 = ''\n",
    "        #print('no annotation \\n')\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        imagenery_value_3 = data['index']['Imagery'][2]['value']\n",
    "    except:\n",
    "        imagenery_value_3 = ''\n",
    "        #print('no annotation \\n')\n",
    "        pass\n",
    "        \n",
    "    try: \n",
    "        imagenery_value_4 = data['index']['Imagery'][3]['value']\n",
    "    except:\n",
    "        imagenery_value_4 = ''\n",
    "        #print('no annotation \\n')\n",
    "        pass\n",
    "        \n",
    "    try: \n",
    "        imagenery_value_5 = data['index']['Imagery'][4]['value']\n",
    "    except:\n",
    "        imagenery_value_5 = ''\n",
    "        #print('no annotation \\n')\n",
    "        pass\n",
    "        \n",
    "    try: \n",
    "        imagenery_value_6 = data['index']['Imagery'][5]['value']\n",
    "    except:\n",
    "        imagenery_value_6 = ''\n",
    "        #print('no annotation \\n')\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        imagenery_value_7 = data['index']['Imagery'][6]['value']\n",
    "    except:\n",
    "        imagenery_value_7 = ''\n",
    "        #print('no annotation \\n')\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        imagenery_value_6 = data['index']['Imagery'][7]['value']\n",
    "    except:\n",
    "        imagenery_value_6 = ''\n",
    "        #print('no annotation \\n')\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        imagenery_value_7 = data['index']['Imagery'][6]['value']\n",
    "    except:\n",
    "        imagenery_value_7 = ''\n",
    "        #print('no annotation \\n')\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        imagenery_value_8 = data['index']['Imagery'][7]['value']\n",
    "    except:\n",
    "        imagenery_value_8 = ''\n",
    "        #print('no annotation \\n')\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        imagenery_value_9 = data['index']['Imagery'][8]['value']\n",
    "    except:\n",
    "        imagenery_value_9 = ''\n",
    "        #print('no annotation \\n')\n",
    "        pass\n",
    "\n",
    "    \n",
    "    annotations = {'filename': f'{ID}.jpg',\n",
    "                    'image_path': f'./art_pieces_thumbnails/images_numpy/{ID}.json',\n",
    "    'tags': ['cameraobscura',\n",
    "            'abandonedbuilding',\n",
    "            'milwaukee',\n",
    "            'pinhole',\n",
    "            'pinholephotography',\n",
    "            'canonmarkiii',\n",
    "            'tiltshiftlens',\n",
    "            'longexposure',\n",
    "            'urbex',\n",
    "            'urbanexploring',\n",
    "            'brewcity',\n",
    "            'canon5dmarkii',\n",
    "            'canon5dmarkiii',\n",
    "            'diyphotography',\n",
    "            'diy'],\n",
    "    'text': 'With in the 5th ward of Milwaukee, WI there has been a variety of '\n",
    "            'changes. Many apartments, condos, restaurants, and bars have been '\n",
    "            'added. The Courteen Seed Company building was created in 1913, and '\n",
    "            \"has been abandoned since 1960's. In 2006, there were plans to \"\n",
    "            'convert there warehouse to apartments/condos, yet minimal '\n",
    "            'maintenance has been done.',\n",
    "    'title': 'Courteen Seed Company VS The 5th Ward'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code is: 200\n",
      "There are 511 pages to be scraped.\n",
      "\n",
      "Scanning page 1 of 511\n",
      "https://collections.louvre.fr/en/recherche?page=1&typology[0]=1 \n",
      "\n",
      "Status code is: 200\n",
      "There are 20 items in this page.\n",
      "\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "max_pages, current_page = get_weblimits(url_base)\n",
    "\n",
    "# 10 webs / 1.5 min\n",
    "\n",
    "for i in range(current_page, 2): #max_pages\n",
    "    #max_pag = max_pag\n",
    "    url_scrap = f'https://collections.louvre.fr/en/recherche?page={i}&typology[{typology_index}]=1'\n",
    "    print(f'Scanning page {i} of {max_pages}')\n",
    "    print(url_scrap, '\\n')\n",
    "\n",
    "    links = get_artworks_links(url_scrap)\n",
    "    print(len(links))\n",
    "    #get_metada_thumbail(links)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "links[1]\n",
    "if os.path.exists(path_annotations_json):\n",
    "        pass\n",
    "else:\n",
    "    os.mkdir(path_annotations_json)\n",
    "\n",
    "if os.path.exists(path_annotations_pickle):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(path_annotations_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./json/cl010052695\n"
     ]
    }
   ],
   "source": [
    "i = links[19]\n",
    "# Get item info\n",
    "metadata = requests.get(url_art_DB_base+ i +'.json').content\n",
    "print(f'./json/{i[-11:]}')\n",
    "\n",
    "with open(f'{path_annotations_json}{i[-11:]}.json', 'wb') as f:\n",
    "    f.write(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open(f'{path_annotations_json}{i[-11:]}.json', 'r')\n",
    "\n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    "\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_to_pickle(ID):\n",
    "    # Opening JSON file\n",
    "    f = open(f'{path_annotations_json}{ID}.json', 'r')\n",
    "\n",
    "    # returns JSON object as\n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "\n",
    "    # Closing file\n",
    "    f.close()\n",
    "\n",
    "    arkId = data['arkId']\n",
    "    title = data['title']\n",
    "    startYear = data['dateCreated'][0]['startYear']\n",
    "    endYear = data['dateCreated'][0]['endYear']\n",
    "    collection = data['collection']\n",
    "    materialsAndTechniques = data['materialsAndTechniques']\n",
    "    category = data['index']['Category'][0]['value']\n",
    "    tags = []\n",
    "\n",
    "    for i in data['index']['Imagery']:\n",
    "        tags.append(i['value'])\n",
    "\n",
    "\n",
    "    data_xml = {}\n",
    "    data_xml[arkId] = {}\n",
    "    data_xml[arkId]['filename'] = f'{path_images_thumbnails}{arkId}.jpg'\n",
    "    data_xml[arkId]['startYear'] = startYear\n",
    "    data_xml[arkId]['endYear'] = endYear\n",
    "    data_xml[arkId]['materialsAndTechniques'] = materialsAndTechniques\n",
    "    data_xml[arkId]['category'] = category\n",
    "    data_xml[arkId]['tags'] = tags\n",
    "    data_xml[arkId]['title'] = title\n",
    "\n",
    "    pickle.dump(data_xml, open(path_annotations_pickle + arkId + \".p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cl010052695\n",
      "cl010244524\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Imagery'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pvillamana\\Desktop\\art_style_extractor\\test_scrap.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pvillamana/Desktop/art_style_extractor/test_scrap.ipynb#ch0000024?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(path_annotations_json):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pvillamana/Desktop/art_style_extractor/test_scrap.ipynb#ch0000024?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(i[:\u001b[39m-\u001b[39m\u001b[39m5\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pvillamana/Desktop/art_style_extractor/test_scrap.ipynb#ch0000024?line=2'>3</a>\u001b[0m     metadata_to_pickle(i[:\u001b[39m-\u001b[39;49m\u001b[39m5\u001b[39;49m])\n",
      "\u001b[1;32mc:\\Users\\pvillamana\\Desktop\\art_style_extractor\\test_scrap.ipynb Cell 12'\u001b[0m in \u001b[0;36mmetadata_to_pickle\u001b[1;34m(ID)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pvillamana/Desktop/art_style_extractor/test_scrap.ipynb#ch0000020?line=17'>18</a>\u001b[0m category \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mCategory\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pvillamana/Desktop/art_style_extractor/test_scrap.ipynb#ch0000020?line=18'>19</a>\u001b[0m tags \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pvillamana/Desktop/art_style_extractor/test_scrap.ipynb#ch0000020?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data[\u001b[39m'\u001b[39;49m\u001b[39mindex\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mImagery\u001b[39;49m\u001b[39m'\u001b[39;49m]:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pvillamana/Desktop/art_style_extractor/test_scrap.ipynb#ch0000020?line=21'>22</a>\u001b[0m     tags\u001b[39m.\u001b[39mappend(i[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pvillamana/Desktop/art_style_extractor/test_scrap.ipynb#ch0000020?line=24'>25</a>\u001b[0m data_xml \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Imagery'"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(path_annotations_json):\n",
    "    print(i[:-5])\n",
    "    metadata_to_pickle(i[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c84532701b596cbbc01b2a415f41af54b6b621a6c4c19998fc70922ae7840e48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mosaic_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
